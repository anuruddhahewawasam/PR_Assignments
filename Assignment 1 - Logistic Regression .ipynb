{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data\\\\breast_cancer_wisconsin_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      "id                         569 non-null int64\n",
      "diagnosis                  569 non-null object\n",
      "radius_mean                569 non-null float64\n",
      "texture_mean               569 non-null float64\n",
      "perimeter_mean             569 non-null float64\n",
      "area_mean                  569 non-null float64\n",
      "smoothness_mean            569 non-null float64\n",
      "compactness_mean           569 non-null float64\n",
      "concavity_mean             569 non-null float64\n",
      "concave points_mean        569 non-null float64\n",
      "symmetry_mean              569 non-null float64\n",
      "fractal_dimension_mean     569 non-null float64\n",
      "radius_se                  569 non-null float64\n",
      "texture_se                 569 non-null float64\n",
      "perimeter_se               569 non-null float64\n",
      "area_se                    569 non-null float64\n",
      "smoothness_se              569 non-null float64\n",
      "compactness_se             569 non-null float64\n",
      "concavity_se               569 non-null float64\n",
      "concave points_se          569 non-null float64\n",
      "symmetry_se                569 non-null float64\n",
      "fractal_dimension_se       569 non-null float64\n",
      "radius_worst               569 non-null float64\n",
      "texture_worst              569 non-null float64\n",
      "perimeter_worst            569 non-null float64\n",
      "area_worst                 569 non-null float64\n",
      "smoothness_worst           569 non-null float64\n",
      "compactness_worst          569 non-null float64\n",
      "concavity_worst            569 non-null float64\n",
      "concave points_worst       569 non-null float64\n",
      "symmetry_worst             569 non-null float64\n",
      "fractal_dimension_worst    569 non-null float64\n",
      "Unnamed: 32                0 non-null float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 32', 'id'], axis = 1) \n",
    "data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.diagnosis.values \n",
    "x_data = data.drop(['diagnosis'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x_data - np.min(x_data))/(np.max(x_data) - np.min(x_data)).values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (32, 483)\n",
      "x test:  (32, 86)\n",
      "y train:  (483,)\n",
      "y test:  (86,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x_test, y_train, y_test = train_test_split( \n",
    "    x, y, test_size = 0.15, random_state = 42) \n",
    "  \n",
    "x_train = x_train.T \n",
    "x_test = x_test.T \n",
    "y_train = y_train.T \n",
    "y_test = y_test.T \n",
    "  \n",
    "print(\"x train: \", x_train.shape) \n",
    "print(\"x test: \", x_test.shape) \n",
    "print(\"y train: \", y_train.shape) \n",
    "print(\"y test: \", y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_bias(dimension): \n",
    "    w = np.full((dimension, 1), 0.01) \n",
    "    b = 0.0\n",
    "    return w, b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    y_head = 1/(1 + np.exp(-z)) \n",
    "    return y_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward_propagation(w, b, x_train, y_train): \n",
    "    z = np.dot(w.T, x_train) + b \n",
    "    y_head = sigmoid(z) \n",
    "    loss = - y_train * np.log(y_head) - (1 - y_train) * np.log(1 - y_head) \n",
    "    # x_train.shape[1]  is for scaling \n",
    "    cost = (np.sum(loss)) / x_train.shape[1]       \n",
    "  \n",
    "    # backward propagation \n",
    "    derivative_weight = (np.dot(x_train, ( \n",
    "        (y_head - y_train).T))) / x_train.shape[1]  \n",
    "    derivative_bias = np.sum( \n",
    "        y_head-y_train) / x_train.shape[1]                  \n",
    "    gradients = {\"derivative_weight\": derivative_weight, \n",
    "                 \"derivative_bias\": derivative_bias} \n",
    "    return cost, gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w, b, x_train, y_train, learning_rate, number_of_iterarion): \n",
    "    cost_list = [] \n",
    "    cost_list2 = [] \n",
    "    index = [] \n",
    "  \n",
    "    # updating(learning) parameters is number_of_iterarion times \n",
    "    for i in range(number_of_iterarion): \n",
    "        # make forward and backward propagation and find cost and gradients \n",
    "        cost, gradients = forward_backward_propagation(w, b, x_train, y_train) \n",
    "        cost_list.append(cost) \n",
    "  \n",
    "        # lets update \n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"] \n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"] \n",
    "        if i % 10 == 0: \n",
    "            cost_list2.append(cost) \n",
    "            index.append(i) \n",
    "            print (\"Cost after iteration % i: % f\" %(i, cost)) \n",
    "  \n",
    "    # update(learn) parameters weights and bias \n",
    "    parameters = {\"weight\": w, \"bias\": b} \n",
    "    plt.plot(index, cost_list2) \n",
    "    plt.xticks(index, rotation ='vertical') \n",
    "    plt.xlabel(\"Number of Iterarion\") \n",
    "    plt.ylabel(\"Cost\") \n",
    "    plt.show() \n",
    "    return parameters, gradients, cost_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, x_test): \n",
    "    # x_test is a input for forward propagation \n",
    "    z = sigmoid(np.dot(w.T, x_test)+b) \n",
    "    Y_prediction = np.zeros((1, x_test.shape[1])) \n",
    "  \n",
    "    # if z is bigger than 0.5, our prediction is sign one (y_head = 1), \n",
    "    # if z is smaller than 0.5, our prediction is sign zero (y_head = 0), \n",
    "    for i in range(z.shape[1]): \n",
    "        if z[0, i]<= 0.5: \n",
    "            Y_prediction[0, i] = 0\n",
    "        else: \n",
    "            Y_prediction[0, i] = 1\n",
    "  \n",
    "    return Y_prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration  0:  nan\n",
      "Cost after iteration  10:  nan\n",
      "Cost after iteration  20:  nan\n",
      "Cost after iteration  30:  nan\n",
      "Cost after iteration  40:  nan\n",
      "Cost after iteration  50:  nan\n",
      "Cost after iteration  60:  nan\n",
      "Cost after iteration  70:  nan\n",
      "Cost after iteration  80:  nan\n",
      "Cost after iteration  90:  nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 37.267080745341616 %\n",
      "test accuracy: 37.2093023255814 %\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(x_train, y_train, x_test, y_test,  \n",
    "                        learning_rate,  num_iterations): \n",
    "  \n",
    "    dimension = x_train.shape[0] \n",
    "    w, b = initialize_weights_and_bias(dimension) \n",
    "      \n",
    "    parameters, gradients, cost_list = update( \n",
    "        w, b, x_train, y_train, learning_rate, num_iterations) \n",
    "      \n",
    "    y_prediction_test = predict( \n",
    "        parameters[\"weight\"], parameters[\"bias\"], x_test) \n",
    "    y_prediction_train = predict( \n",
    "        parameters[\"weight\"], parameters[\"bias\"], x_train) \n",
    "  \n",
    "    # train / test Errors \n",
    "    print(\"train accuracy: {} %\".format( \n",
    "        100 - np.mean(np.abs(y_prediction_train - y_train)) * 100)) \n",
    "    print(\"test accuracy: {} %\".format( \n",
    "        100 - np.mean(np.abs(y_prediction_test - y_test)) * 100)) \n",
    "      \n",
    "logistic_regression(x_train, y_train, x_test, y_test, learning_rate = 1, num_iterations = 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-31e0a2fa5964>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m print(\"test accuracy: {} \".format( \n\u001b[1;32m----> 4\u001b[1;33m     logreg.fit(x_train.T, y_train.T).score(x_test.T, y_test.T))) \n\u001b[0m\u001b[0;32m      5\u001b[0m print(\"train accuracy: {} \".format( \n\u001b[0;32m      6\u001b[0m     logreg.fit(x_train.T, y_train.T).score(x_train.T, y_train.T))) \n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1288\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1289\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model \n",
    "logreg = linear_model.LogisticRegression(random_state = 42, max_iter = 150) \n",
    "print(\"test accuracy: {} \".format( \n",
    "    logreg.fit(x_train.T, y_train.T).score(x_test.T, y_test.T))) \n",
    "print(\"train accuracy: {} \".format( \n",
    "    logreg.fit(x_train.T, y_train.T).score(x_train.T, y_train.T))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
